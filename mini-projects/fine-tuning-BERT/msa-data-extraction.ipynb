{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8986364,"sourceType":"datasetVersion","datasetId":5412063}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bs4 import BeautifulSoup\ndef extract_domains(file_name: str):\n    # Open the file in read mode\n    with open(file_name, \"r\") as f:\n        # Read lines directly from the file\n        soup = f.read()\n    bs = BeautifulSoup(soup,\"html.parser\")\n    # Find all elements with the specified class\n    elements = bs.find_all(class_=\"blob-code blob-code-inner js-file-line\")\n\n    # Extract the text from each element\n    data = [element.get_text(strip=True) for element in elements]\n\n    # Create a DataFrame\n    df = pd.DataFrame(data, columns=['domains'])\n    return df\n# https://data.mendeley.com/datasets/gwnwdgzts3/1\nsafe_domains = extract_domains(\"/kaggle/input/domains-list/clean-alexa-32k.txt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"malicious_domains = pd.read_csv('/kaggle/input/domains-list/malicious-domains-20240718.txt', header = None, names = ['domains'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_safe_domains = safe_domains.sample(150).reset_index(drop = True)\nsub_malicious_domains = malicious_domains.sample(150).reset_index(drop = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**AlienVault**","metadata":{}},{"cell_type":"code","source":"# whois only\n# https://otx.alienvault.com/assets/static/external_api.html#\nimport requests\ndef get_domain_data(api_key, domain, section):\n    \"\"\"\n    Fetch data for a given domain using the AlienVault API.\n\n    Parameters:\n        api_key (str): Your AlienVault API key.\n        domain (str): The domain to fetch data for.\n\n    Returns:\n        dict: A dictionary containing the domain data if successful, otherwise None.\n    \"\"\"\n    # Define the base URL for the AlienVault API\n    url = f\"https://otx.alienvault.com/api/v1/indicators/domain/{domain}/{section}\"\n    headers = {\n        'X-OTX-API-KEY': api_key  # Include your API key in the request headers\n    }\n    \n    try:\n        # Make a GET request to the API\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()  # Raise an error for bad responses\n        return response.json()  # Return the JSON data if successful\n    except requests.exceptions.RequestException as e:\n        print(f\"Error fetching data for domain {domain}: {e}\")\n        return None  # Return None if there was an error\n\ndef fetch_data_for_domains(domains, api_key, section):\n    \"\"\"\n    Fetch data for a list of domains and return a DataFrame containing the results.\n\n    Parameters:\n        domains (list): A list of domain names to fetch data for.\n        api_key (str): Your AlienVault API key.\n\n    Returns:\n        DataFrame: A Pandas DataFrame containing the domain data.\n    \"\"\"\n    data_dict = {}  # List to store the domain data\n    for domain in domains:\n        domain_data = get_domain_data(api_key, domain, section)  # Fetch data for each domain\n        if domain_data:\n            data_dict[domain] = domain_data  # Add the data to the dictionary if it was successfully fetched\n    \n    # Create a DataFrame from the data list\n    df = pd.DataFrame.from_dict(data_dict).T\n    return df  # Return the DataFrame","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Indicator page api for domain names\n\nExample domains: 'rghost.net', 'spywaresite.info'\n\nsections:\n\n* general: General information about the domain, including any pulses, and a list of the other sections currently available for this domain.\n* geo: A more verbose listing of geographic data (Country code, coordinates, etc.)\n* malware: Malware samples analyzed by LevelBlue Labs which have been observed connecting to this domain.\n* url_list: URLs analyzed by LevelBlue Labs on this domain.\n* passive_dns: Passive dns records observed by LevelBlue Labs pointing to this domain.\n* whois: Whois records for the domain.\n* http_scans: Meta data for http(s) connections to the domain.","metadata":{}},{"cell_type":"code","source":"import json\n\ndef json_to_string(json_obj):\n    \"\"\"\n    Convert a JSON object or a list of JSON objects to a string representation of key-value pairs.\n    \n    :param json_obj: A JSON object, a list of JSON objects, or a string representation of either\n    :return: A string representation of the JSON object(s) key-value pairs\n    \"\"\"\n    \n    # If the input is a string, try to parse it as JSON\n    if isinstance(json_obj, str):\n        try:\n            json_obj = json.loads(json_obj)\n            print(\"Successfully parsed JSON string\")\n        except json.JSONDecodeError as e:\n            print(f\"Failed to parse JSON string: {e}\")\n            return \"Invalid JSON string\"\n    \n    # If it's a list, process each item in the list\n    if isinstance(json_obj, list):\n        return '; '.join([process_dict(item) if isinstance(item, dict) else str(item) for item in json_obj])\n    \n    # If it's a dictionary, process it\n    elif isinstance(json_obj, dict):\n        return process_dict(json_obj)\n    \n    # If it's neither a list nor a dictionary, return an error message\n    else:\n        print(f\"Input is not a list or dictionary\")\n        return \"Input is not a valid JSON object or list of objects\"\n\ndef process_dict(d):\n    \"\"\"Helper function to process a single dictionary, extracting only 'key' and 'value'\"\"\"\n    if 'key' in d and 'value' in d:\n        return f\"{d['key']}: {d['value']}\"\n    else:\n        return \"Invalid dictionary format\"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"api_key = 'AlienVaultKey'  # Replace with your AlienVault API key\nsection = 'whois'\n\ndef process_domains(domains_df, label, api_key, section):\n    \"\"\"\n    Process a DataFrame of domains, fetch data for them, and prepare the result DataFrame.\n\n    :param domains_df: DataFrame containing domains\n    :param label: Label for the domains ('safe' or 'malicious')\n    :param api_key: API key for fetching data\n    :param section: Section to fetch data from\n    :return: Processed DataFrame\n    \"\"\"\n    domains_list = domains_df['domains'].tolist()\n    \n    # Fetch data for the specified domains\n    df = fetch_data_for_domains(domains_list, api_key, section)\n    \n    # Process the fetched data\n    df = df.reset_index(names='domain')\n    df['text'] = df['data'].apply(json_to_string)\n    df['label'] = label\n    \n    return df\n\n# Process safe domains\nsafe_df = process_domains(sub_safe_domains, 'safe', api_key, section)\n\n# Process malicious domains\nmalicious_df = process_domains(sub_malicious_domains, 'malicious', api_key, section)\n\n# Combine safe and malicious DataFrames if needed\ncombined_df = pd.concat([safe_df.drop(['data', 'count','related'], axis = 1), malicious_df.drop(['data', 'count','related'], axis = 1)], ignore_index=True)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_df1 = combined_df[combined_df['text'] != '']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_df1['label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_df1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the DataFrame to a CSV file\ncombined_df1.to_csv('/kaggle/working/combined_data.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}