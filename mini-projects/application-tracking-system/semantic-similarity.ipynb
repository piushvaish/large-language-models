{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Semantic Similarity \nIt is the similarity between two words or two sentences/phrase/text. It measures how close or how different the two pieces of word or text are in terms of their meaning and context.","metadata":{}},{"cell_type":"code","source":"!pip install -U -qq transformers accelerate sentence-transformers","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\n\ndef semantic_similarity_sbert_base_v2(job,resume, model):\n    \"\"\"calculate similarity with SBERT all-mpnet-base-v2\"\"\"\n    model = SentenceTransformer(model)\n    # Compute embedding for both lists\n    embeddings1 = model.encode(job, convert_to_tensor=True)\n    embeddings2 = model.encode(resume, convert_to_tensor=True)\n\n    # Compute cosine-similarities\n    cosine_scores = util.cos_sim(embeddings1, embeddings2)\n     \n    return cosine_scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"job_description = \"\"\"\n\nAs a member of the IBM Software development team, you will:\nAnalyze and develop data models and schemes to ensure that data structures adequately support business requirements and facilitate analysis within a data warehouse environment.\nDevelop and test database queries to assess performance impacts and troubleshoot any issues that arise.\nTranslate intricate functional and technical requirements into detailed architecture, design, and high-performing reporting solutions.\nCollaborate with business and internal stakeholders to clarify requirements and validation criteria.\nDesign and implement analyses, metrics, reports, and dashboards to provide comprehensive insights into the efficiency and effectiveness of each function, aiming to identify opportunities for added value.\n\nRequired Technical and Professional Expertise\n\nAdvanced SQL proficiency of designing and optimizing complex queries is essential.\nMinimum of 2 years of experience in Python programming.\nMinimum of 2 years of experience in data roles (such as Analytics Engineering, Data Engineering, Data Analysis).\nExperience with Microsoft Excel VBA.\nExperience with data warehouse systems and operational reporting systems.\nFamiliarity with ETL processes and data modeling.\nExperience with Star or Snowflake schemas and dashboard development in Cognos.\nExcellent problem-solving and critical thinking abilities.\nUnderstanding of design thinking.\n\nPreferred Technical and Professional Expertise\n\nExperience developing front-end applications using React.js, JavaScript, TypeScript, HTML, and CSS.\nSoftware programming experience in Python, SQL, Node.js, and REST API.\nAbility to foster trust and rapport to create a comfortable and effective workplace environment.\nDegree in Information Technology or Computer Science.\n\n\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resume = \"\"\"\n\n\n\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"semantic_similarity_sbert_base_v2(job_description,resume, 'all-MiniLM-L12-v1')","metadata":{},"execution_count":null,"outputs":[]}]}