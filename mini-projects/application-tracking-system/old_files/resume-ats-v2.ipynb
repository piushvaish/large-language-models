{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8160381,"sourceType":"datasetVersion","datasetId":4827851}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U -qq transformers accelerate bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-04-26T22:26:06.284809Z","iopub.execute_input":"2024-04-26T22:26:06.285203Z","iopub.status.idle":"2024-04-26T22:26:36.542211Z","shell.execute_reply.started":"2024-04-26T22:26:06.285170Z","shell.execute_reply":"2024-04-26T22:26:36.541136Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**Context**\n\nYou spend hours perfecting your resume, making sure it outlines your skills and experience in the best possible light. After all, when it comes to job hunting, your resume is your most important tool.\n\nBut after all that work, you’re still not getting enough interviews, even for jobs you know you’re qualified for. Why not?\n\nWhat you might not realize is that your resume usually doesn’t go to a human being after you submit it – it goes to a computer. In fact, there’s a good chance a real person will never see your resume!\n\nThat’s because more and more employers are using applicant tracking systems (ATS) to screen resumes. \n\nWhat is an ATS? It’s computer software designed to scan resumes for certain keywords and weed out the ones that don’t match the job description.\n\nSo if you want your resume to actually make it into the hands of a human being, you need to make sure it’s optimized for the ATS.\n\nIn this notebook, we’re going to use NLP and language models to create a resume that can \"pass\" ATS!\n\n**How applicant tracking systems work?**\nThere are 4 basic steps to how an applicant tracking system works:\n\n1. A job requisition enters into the ATS. This requisition includes information about the position, such as the job title, desired skills, and required experience.\n2. The ATS then uses this information to create a profile for the ideal candidate.\n3. As applicants submit their resumes, the ATS parses, sorts, and ranks them based on how well they match the profile.\n4. Hiring managers then quickly identify the most qualified candidates and move them forward in the hiring process.\n\nWhat’s especially important to understand is that recruiters often filter resumes by searching for key skills and job titles.\n\nThis means that if you can predict the resume keywords that recruiters will use in their search, you’ll greatly increase your chances of moving on in the hiring process. But you don’t have to guess which keywords to use. All you have to do is analyze the job description to find them.\n\nThis notebook automates this process by using AI technology to analyze resume against the job description. It then provides a score that shows how well your resume matches the job description.","metadata":{}},{"cell_type":"markdown","source":"**Who uses ATS?**\nOver 97% of Fortune 500 companies use ATS while a Kelly OCG survey estimated that 66% of large companies and 35% of small organizations rely on recruitment software. And these numbers continue to grow.\n\nIf you’re applying to a large organization, you’ll most likely face an ATS. \n\nIf you’re applying through any online form, you’re applying through an ATS. \n\nEven job sites like Indeed and LinkedIn have their own built-in ATS.\n\nIt’s clear that ATS is here to stay. That’s why it’s so important to use the right keywords and format your resume in a way that makes it easy for ATS software to read.\n\n**How to optimize your resume for an ATS?**\n1. Carefully tailor your resume to the job description every single time you apply.\n2. Optimize for ATS search and ranking algorithms by matching your resume keywords to the job description.\n3. Use both the long-form and acronym version of keywords (e.g. “Master of Business Administration (MBA)” or “Search Engine Optimization (SEO)”) for maximum searchability.\n4. Use a chronological or hybrid resume format (avoid the functional resume format).\n5. Use a traditional resume font like Helvetica, Garamond, or Georgia.\n6. Don’t use headers or footers as the information might get lost or cause a parsing error.\n7. Use standard resume section headings like “Work Experience” rather than being cute or clever (“Where I’ve Been”).\n8. Use an ATS-friendly resume builder to create your resume.","metadata":{}},{"cell_type":"markdown","source":"### Keyword Extraction\n","metadata":{}},{"cell_type":"markdown","source":"### Extracting Job Skills using LLMs\n\nTF-IDF needs a lot of processing and does not work as efficently. Classical NLP tools do not extract all the key words.\n\nThe idea of extracting keywords from documents through an LLM is straightforward and allows for easily testing your LLM and its capabilities.\n\n**Why Mistral 7B model?**\nMistral 7B is a 7-billion-parameter language model released by Mistral AI. Mistral 7B is a carefully designed language model that provides both efficiency and high performance to enable real-world applications. Due to its efficiency improvements, the model is suitable for real-time applications where quick responses are essential.\n\nMistral 7B has demonstrated superior performance across various benchmarks, outperforming even models with larger parameter counts. It excels in areas like mathematics, code generation, and reasoning.\n\n* https://www.linkedin.com/pulse/proof-concept-using-large-language-models-llms-extract-truc-phan-w5vde/\n* https://huggingface.co/docs/transformers/main/en/model_doc/llama2\n* https://huggingface.co/blog/llama2#how-to-prompt-llama-2\n* https://colab.research.google.com/drive/1ge2F1QSK8Q7h0hn3YKuBCOAS0bK8E0wf?usp=sharing\n* https://towardsdatascience.com/meta-llama-3-optimized-cpu-inference-with-hugging-face-and-pytorch-9dde2926be5c\n* https://www.promptingguide.ai/models/mistral-7b","metadata":{}},{"cell_type":"markdown","source":"Experimented with\n* ","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login, Repository\n\n# Login to Hugging Face\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-26T22:26:36.544358Z","iopub.execute_input":"2024-04-26T22:26:36.544751Z","iopub.status.idle":"2024-04-26T22:26:36.992013Z","shell.execute_reply.started":"2024-04-26T22:26:36.544700Z","shell.execute_reply":"2024-04-26T22:26:36.990687Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7788232aa96143f1b80620d628dffea4"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nfrom transformers import BitsAndBytesConfig\nimport torch\nimport time\nimport regex\nimport json\n\nmodel_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n#TOKEN = TOKEN\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    llm_int8_enable_fp32_cpu_offload=True,\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(model_name, \n                                             device_map=\"auto\", \n                                             quantization_config=bnb_config)\n                                             #token=TOKEN)\ntokenizer = AutoTokenizer.from_pretrained(model_name, \n                                          use_fast=True, \n                                          quantization_config=bnb_config)\n                                          #token=TOKEN)\n# Define a pattern to match JSON object\npattern = regex.compile(r'\\{(?:[^{}]|(?R))*\\}')","metadata":{"execution":{"iopub.status.busy":"2024-04-26T23:46:27.965634Z","iopub.execute_input":"2024-04-26T23:46:27.966482Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"markdown","source":"#### Extract Skills","metadata":{}},{"cell_type":"code","source":"skills = \"\"\"\n\nExpertise in machine learning algorithms, including linear regression, clustering, classification, and recommendation systems\nProven ability to create clear, concise, and compelling visualizations using tools like ggplot2, matplotlib, or plotly, Power BI, Tableau, and Qlik\nConceptual understanding of data analysis fundamentals, encompassing ETL, data warehousing, and unstructured data\nA comprehensive grasp of deep learning fundamentals, including activation functions, backpropagation, CNNs, Transformers, transfer learning, and generative models Expertise in evaluating and selecting the most appropriate deep learning model for a given task, including assessing model performance metrics, identifying potential biases, and comparing different model architectures\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-26T23:55:54.775811Z","iopub.execute_input":"2024-04-26T23:55:54.776804Z","iopub.status.idle":"2024-04-26T23:55:54.781684Z","shell.execute_reply.started":"2024-04-26T23:55:54.776770Z","shell.execute_reply":"2024-04-26T23:55:54.780793Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"prompt = f\"\"\"\nPlease respond only in the English language. \nDo not explain what you are doing. \nDo not self reference. \n\nYou are an expert text analyst and researcher. \nPlease extract only the most relevant keywords and key phrases from the provided \n{skills}.\n\nExtract keywords for \ndata science related skills,  \nmachine learning techniques, \ndata analysis tools,  \nprogramming languages, \neducational qualifications,\nexperience with number of years,\nand soft skills. \n\nDo not add any unneccesary details. \n\nGenerate a valid JSON object with following key artifacts:\nskills: [],\nmachine learning techniques: [],\ntools: [],\nprogramming_languages: [],\neducation: [],\nexperience: [],\nsoft_skills : []\n\nAVOID adding any details if not explicitly mentioned.\nJust generate the JSON object without explanation, unique words or duplicates. Be brief.\n\nSKILLS & QUALIFICATIONS\n{skills}\n\n\"\"\"\nstart = time.time()\nmodel_inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n\noutput = model.generate(**model_inputs,\n                          max_new_tokens=1024,\n                          repetition_penalty=1.5)\n\ntext_string = tokenizer.decode(output[0], \n                       skip_special_tokens=True)\n\n# Find JSON object using regular expression\njson_match = pattern.findall(text_string)\n\nprint(eval(str(json_match).strip('[]')))\n    \nend = time.time()\nprint(f\"Time (minutes): {(end - start)}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-26T23:55:55.250514Z","iopub.execute_input":"2024-04-26T23:55:55.251266Z","iopub.status.idle":"2024-04-26T23:56:10.581148Z","shell.execute_reply.started":"2024-04-26T23:55:55.251235Z","shell.execute_reply":"2024-04-26T23:56:10.580171Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"{\n\"skills\": [\"expertise\", \"linear regression\",\"clustering\", \"classification\", \"recommendation systems\"],\n   \t     \"machinelearningtechniques\":[\"regression\", \"clusterings\", \"classifcations\", \"deep-Learning\"],\n        \"tools\": [\"ggplot2\", \"matplotlib\", \"plotly\", \"PowerBI\", \"Tableau\", \"Qlik\"],\n         \"programmlangages\":\"NA\", // no mention was made about programming langauge(s) used by this person so we leave it as NA (not applicable),\n          \"education\":[],// No educational background information is available here.,\n           \"experience\":[],\"soft_skills\":[\"provenability\"]}\nTime (minutes): 15.322378396987915\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Extract Job Resposibilities","metadata":{}},{"cell_type":"code","source":"responsibility = \"\"\"\n\nWork closely with the client (PO) as well as other Team Leads to clarify the tech requirements and expectations\n Translate complex business problems into actionable data-driven questions or hypotheses. This will involve working with stakeholders to understand the underlying issues and defining the specific questions that need to be answered through data analysis\n Collect data from various sources, identify and address data quality issues, and convert the data into a format suitable for analysis and modeling. This will involve using data wrangling techniques, data cleaning tools, and data quality checks\n Apply statistical methods, data visualization techniques, and machine learning algorithms to uncover hidden patterns, trends, and anomalies within the data. These insights will inform the development of effective models and solutions\nSelect and apply appropriate machine learning or statistical models to address specific business problems. This involves understanding the problem at hand, choosing the right algorithms, training the models on the prepared data, and evaluating their performance\n Work with engineers to integrate trained models into production environments, ensuring that they can be used to make real-time predictions or decisions. This involves deploying the models, monitoring their performance, and maintaining them over time\nEffectively communicate complex data-driven insights and recommendations to stakeholders in a clear, concise, and actionable manner. This involves using storytelling techniques, visualizations, and presentations to effectively convey the findings and their implications for business decisions\nContinuously research and stay up-to-date with the latest advancements in data science, including new algorithms, techniques, and tools, and explore emerging technologies and methodologies. This involves attending conferences, reading research papers, and experimenting with new approaches\nSuggest and contribute to training and improvement plans regarding analytical data engineering skills, standards, and processes\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-26T23:57:00.617645Z","iopub.execute_input":"2024-04-26T23:57:00.618322Z","iopub.status.idle":"2024-04-26T23:57:00.624439Z","shell.execute_reply.started":"2024-04-26T23:57:00.618291Z","shell.execute_reply":"2024-04-26T23:57:00.623335Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"resp_prompt = f\"\"\" \nPlease respond only in the English language. \nDo not explain what you are doing. \nDo not self reference. \nYou are an expert text analyst. \nPlease list all the main responsibilities, tasks and keywords from the following:\n{responsibility}\n\nResponsibilities are duties that you will carry out on a regular basis.\nTasks are the specific actions that you will perform.\nExtract the keywords mentioned for the position.\n\nDO NOT LIMIT the responsibilities, tasks or keywords.\n\nGenerate a valid JSON object with following key artifact:\n\"responsibilities\": [],\n\"tasks\": [],\n\"keywords\": []\n\nJust generate the JSON object without duplicates.\nAVOID adding any details if not explicitly mentioned.\nEnsure there are no spelling and grammar mistakes.\n\n\n\"\"\"\n\nresp_model_inputs = tokenizer(resp_prompt, return_tensors=\"pt\").to(\"cuda:0\")\n\nresp_output = model.generate(**resp_model_inputs,\n                          max_new_tokens=1024,\n                          repetition_penalty=1.5)\n\nresp_text_string = tokenizer.decode(resp_output[0], \n                       skip_special_tokens=True)\n\n# Find JSON object using regular expression\nresp_json_match = pattern.findall(resp_text_string)\n\n# Print the dictionary\nprint(eval(str(resp_json_match).strip('[]')))\n    \nend = time.time()\nprint(f\"Time (minutes): {(end - start)}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-26T23:57:03.573626Z","iopub.execute_input":"2024-04-26T23:57:03.574499Z","iopub.status.idle":"2024-04-26T23:57:32.657149Z","shell.execute_reply.started":"2024-04-26T23:57:03.574467Z","shell.execute_reply":"2024-04-26T23:57:32.656127Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"{\n    \"responsabilities\": [\n        \"work closely with clients\",\n        \"clarifying technical requirements\",\n        \"translate complex business problems\",\n        \"defining specific questions\",\n        \"collecting data\",\n        \"addressing data quality issues\",\n        \"converting data formats\",\n        \"applying statistical methods\",\n        \"data visualisation techniques\",\n        \"machine learning algorithms\",\n        \"uncover hidden patterns/trends/anomalies\",\n        \"developing effective models/solutions\",\n        \"integrate models into production environment\",\n        \"making real-time predictions/decisions\",\n        \"monitor model performances\",\n        \"maintaining deployed models\",\n        \"communicating results clearly\",\n        \"stay updated with advances in data science\",\n        \"contribute to skill improvements\"\n    ],\n    \t\"tasks\":[],\n      \"keywords\":[\n          \"working with PO's \",\n           \"translating business problems\",\n            \"asking data driven question\",\n             \"identifying data quality issue\",\n              \"preparing data for modelling\",\n               \"using statistics & ML algos\",\n                 \"selecting correct algo\",\n                  \"training ml models\",\n                   \"evaluating algorithm perf.\",\n                       \"deploying predictive systems\",\n                         \"presenting finding succinctly\",\n                          \"researching newest DS developments\"\n      ]}\nTime (minutes): 97.39841675758362\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Summary**","metadata":{}},{"cell_type":"code","source":"profile = \"\"\"\n\nAnalytical and Problem-Solving Skills:\nDemonstrated problem-solving and analytical thinking skills, with a proven track record of applying these skills to real-world challenges to identify problems, gather relevant data, and develop creative solutions\nContinuous learning mindset, ensuring you stay up-to-date with the latest advancements in deep learning and adapt skills accordingly\nActively participate in the evaluation of new tools for analytical data engineering or data science\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-26T23:58:25.862134Z","iopub.execute_input":"2024-04-26T23:58:25.862519Z","iopub.status.idle":"2024-04-26T23:58:25.867202Z","shell.execute_reply.started":"2024-04-26T23:58:25.862487Z","shell.execute_reply":"2024-04-26T23:58:25.866234Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"sum_prompt = f\"\"\" \nCan you provide a comprehensive summary of the given \n{profile}? \n\nThe summary should cover all the key points and main ideas presented in the original text, \nwhile also condensing the information into a concise and easy-to-understand format. \nPlease ensure that the summary includes relevant details and examples that support the main ideas, \nwhile avoiding any unnecessary information or repetition. \nThe length of the summary should be appropriate for the length and complexity of the original text, \nproviding a clear and accurate overview without omitting any important information.\n\nRewrite the summary in first person narrative, active voice, that is professional yet concise.\n\nGenerate a valid JSON object with following key artifact:\n\"summary\": \"\"\n\n\n\"\"\"\n\nsum_model_inputs = tokenizer(sum_prompt, return_tensors=\"pt\").to(\"cuda:0\")\n\nsum_output = model.generate(**sum_model_inputs,\n                          max_new_tokens=512,\n                          repetition_penalty=1.0)\n\nsum_text_string = tokenizer.decode(sum_output[0], \n                       skip_special_tokens=True)\n\n# Find JSON object using regular expression\nsum_json_match = pattern.findall(sum_text_string)\n\n# Print the dictionary\nprint(eval(str(sum_json_match).strip('[]')))\n    \nend = time.time()\nprint(f\"Time (minutes): {(end - start)}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T00:01:44.096420Z","iopub.execute_input":"2024-04-27T00:01:44.096807Z","iopub.status.idle":"2024-04-27T00:01:58.222285Z","shell.execute_reply.started":"2024-04-27T00:01:44.096778Z","shell.execute_reply":"2024-04-27T00:01:58.221232Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"{\n  \"summary\": \"I possess a problem-solving and analytical mindset, demonstrated through my ability to identify challenges, gather data, and develop solutions. I maintain a continuous learning mindset, staying updated with deep learning advancements and adapting skills. I evaluate new tools for analytical data engineering and data science.\"\n}\nTime (minutes): 362.9635200500488\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Prompt 1:**\n\n“Could you please provide a concise and comprehensive summary of the given text? The summary should capture the main points and key details of the text while conveying the author's intended meaning accurately. Please ensure that the summary is well-organized and easy to read, with clear headings and subheadings to guide the reader through each section. The length of the summary should be appropriate to capture the main points and key details of the text, without including unnecessary information or becoming overly long.”\n\n**Prompt 2:**\n“Could you please provide a summary of the given text, including all key points and supporting details? The summary should be comprehensive and accurately reflect the main message and arguments presented in the original text, while also being concise and easy to understand. To ensure accuracy, please read the text carefully and pay attention to any nuances or complexities in the language. Additionally, the summary should avoid any personal biases or interpretations and remain objective and factual throughout.\"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Semantic Similarity \nIt is the similarity between two words or two sentences/phrase/text. It measures how close or how different the two pieces of word or text are in terms of their meaning and context.","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\n\ndef semantic_similarity_sbert_base_v2(job,resume, model):\n    \"\"\"calculate similarity with SBERT all-mpnet-base-v2\"\"\"\n    model = SentenceTransformer(model)\n    # Compute embedding for both lists\n    embeddings1 = model.encode(job, convert_to_tensor=True)\n    embeddings2 = model.encode(resume, convert_to_tensor=True)\n\n    # Compute cosine-similarities\n    cosine_scores = util.cos_sim(embeddings1, embeddings2)\n     \n    return cosine_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resume = \"\"\"\n\n\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"semantic_similarity_sbert_base_v2(job,resume, 'all-MiniLM-L12-v1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### How to Conduct Candidate Analysis\n\nCrafting a comprehensive candidate analysis involves multiple dimensions. Here are the key steps:\n\n1. Resume Keyword Matching: Verify alignment between the resume and job description by looking for overlaps in skills and experience.\n2. Competency-Based Evaluation: Scrutinize past achievements using the STAR technique to ensure competencies match those necessary for the role.\n3. AIDA Cover Letter Review: Evaluate the cover letter to see if it effectively grabs Attention, maintains Interest, builds Desire, and prompts Action.\n4. Fit/Gap Analysis: Determine where a candidate’s skills meet the job prerequisites and where they don't to assess overall compatibility.\n5. Growth Potential Assessment: Consider the candidate's past trajectories to estimate their potential for future growth within your startup.","metadata":{}},{"cell_type":"markdown","source":"**ChatGPT Prompt for Founders to Create Candidate Analysis**\n\n\nUsing the job description provided, I need a detailed **candidate analysis report** for a job application. This report will assist me in making an informed decision about whether to proceed with the interview process for this candidate.\n\nHere is the job description to use as a benchmark:\n\n[Job Description]\n\n#### Candidate’s Application Analysis:\n\n1. **Resume Keyword Match**: Examine the applicant's resume and extract key skills, experiences, and qualifications. Present these in a bullet-pointed list and note which directly match the job description criteria.\n\n2. **Competency-Based Evaluation**: Analyze the candidate's strongest work achievements. Use the STAR technique to break these down and comment on how these achievements demonstrate competencies required for the job.\n\n3. **Cover Letter AIDA Assessment**: Critique the cover letter using the AIDA model, focusing on how the candidate uses it to illustrate suitability for the role.\n\n4. **Fit-Gap Analysis**: Conduct a fit-gap analysis by creating two lists: one showing where the candidate's skills and experiences match the job requirements ('Fit') and another where they do not align ('Gap').\n\n5. **Growth Potential**: Comment briefly on the candidate's potential for growth and learning within the company based on their career trajectory and achievements presented.\n\n6. **Final Suitability Statement**: Conclude with a suitability statement summarizing whether the candidate should be considered for the role  based on criteria matches, potential growth, and overall fit for the company culture.\n\nPlease present your findings in a cohesive markdown format, ensuring each section is clear and well-structured for ease of review.\n\nCandidate's Application:\n\n[Candidate Application]\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}