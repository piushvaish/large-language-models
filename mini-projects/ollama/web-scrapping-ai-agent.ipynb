{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"[ScrapeGraphAI](https://github.com/VinciGit00/Scrapegraph-ai) is a web scraping python library that uses LLM and direct graph logic to create scraping pipelines for websites and local documents (XML, HTML, JSON, etc.).\n\nJust say which information you want to extract and the library will do it for you!\n\n### Step1: Install the necessary Python Libraries","metadata":{}},{"cell_type":"code","source":"!pip -qq install scrapegraphai\n!playwright install\n!playwright install-deps","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step2 : Download ollama and pull the following models:\n\n* Llama-3 as the main LLM\n* nomic-embed-text as the embedding model","metadata":{}},{"cell_type":"code","source":"!curl https://ollama.ai/install.sh | sh","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ollama","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step2 - Run the app","metadata":{}},{"cell_type":"code","source":"import subprocess\nimport time\n\n# Start ollama as a backrgound process\ncommand = \"nohup ollama serve&\"\n\n# Use subprocess.Popen to start the process in the background\nprocess = subprocess.Popen(command,\n                            shell=True,\n                           stdout=subprocess.PIPE,\n                           stderr=subprocess.PIPE)\nprint(\"Process ID:\", process.pid)\n# Let's use fly.io resources\n#!OLLAMA_HOST=https://ollama-demo.fly.dev:443\ntime.sleep(5)  # Makes Python wait for 5 seconds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ollama list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 3: Get the Model\nNext, you can visit the model library to check the list of all model families currently supported. The default model downloaded is the one with the latest tag. On the page for each model, you can get more info such as the size and quantization used.\n\nYou can search through the list of tags to locate the model that you want to run. For each model family, there are typically foundational models of different sizes and instruction-tuned variants.","metadata":{}},{"cell_type":"code","source":"!ollama pull llama3\n!ollama pull nomic-embed-text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 3: Check that Ollama is running \nTry serving the model with the command\n\n","metadata":{}},{"cell_type":"code","source":"#!ollama run llama3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!ollama serve llama3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scrapegraphai.graphs import SmartScraperGraph\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"ollama/llama3\",\n        \"temperature\": 0,\n        \"format\": \"json\",  # Ollama needs the format to be specified explicitly\n        #\"base_url\": \"http://localhost:11434\",  # set Ollama URL\n    },\n    \"embeddings\": {\n        \"model\": \"ollama/nomic-embed-text\",\n        #\"base_url\": \"http://localhost:11434\",  # set Ollama URL\n    },\n    \"verbose\": True,\n}\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their descriptions\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://perinim.github.io/projects\",\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}