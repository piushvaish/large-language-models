{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U -qq sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-04-15T01:58:44.512117Z","iopub.execute_input":"2024-04-15T01:58:44.512659Z","iopub.status.idle":"2024-04-15T01:59:02.757990Z","shell.execute_reply.started":"2024-04-15T01:58:44.512618Z","shell.execute_reply":"2024-04-15T01:59:02.755835Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**What is Semantic Search?**\nSemantic search goes beyond keyword search (which relies on the occurrence of specific index words in the search input) to find contextually relevant data based on the conceptual similarity of the input string. \n\n| Data | source |\n_________________\n\n| Search | method |\n___________________\n\n| Document management systems (Google Drive, Sharepoint, etc.) | Keyword search, custom query string |\n______________________________________________________________________________________________________\n\n| Relational databases (Postgres, MySQL, etc.) | SQL query |\n____________________________________________________________\n\n| Vector databases | Semantic search query |\n____________________________________________________________\n\n \nAs a result, it has been a good choice for providing more context to models like GPT-4 (since queries are likely to be heavily context dependent). Semantic search uses a vector database, which stores text chunks (derived from some documents) and their vectors (mathematical representations of the text). When you query a vector database, the search input (in vector form) is compared to all of the stored vectors, and the most similar text chunks are returned.\n\nExample of semantic search\n\nLet’s say that you are building a customer support chatbot. If you want to populate a vector database with articles from a knowledge base, you might:\n\n1. Break each of the articles up into chunks. This could be at the sentence, paragraph, or page level. Different chunking strategies will yield different results.\n2. Use the OpenAI Embedding API to process those chunks and return embeddings (i.e. mathematical representations of the nature of the chunk in vector space). F4. or example: [ -0.006929283495992422,-0.005336422007530928, … -4.547132266452536e-05, -0.024047505110502243]\n3. Store the chunks and their embeddings in the database. When a user asks the chatbot a question, a semantic search is performed:\n\n4. User submits a query like “How can I use the OpenAI API?” Use the OpenAI Embedding API to produce a vector representation of the query string\n\n5. Submit that vector to the search endpoint associated with my vector db. Get back one or more text chunks which are similar to my query.\n\nSemantic search seeks to improve search accuracy by understanding the content of the search query. In contrast to traditional search engines which only find documents based on lexical matches, semantic search can also find synonyms.\n\nBackground\nThe idea behind semantic search is to embed all entries in your corpus, whether they be sentences, paragraphs, or documents, into a vector space.\n\nAt search time, the query is embedded into the same vector space and the closest embeddings from your corpus are found. These entries should have a high semantic overlap with the query.\n\nSymmetric vs. Asymmetric Semantic Search\nA critical distinction for your setup is symmetric vs. asymmetric semantic search:\n\nFor symmetric semantic search your query and the entries in your corpus are of about the same length and have the same amount of content. An example would be searching for similar questions: Your query could for example be “How to learn Python online?” and you want to find an entry like “How to learn Python on the web?”. For symmetric tasks, you could potentially flip the query and the entries in your corpus.\n\nFor asymmetric semantic search, you usually have a short query (like a question or some keywords) and you want to find a longer paragraph answering the query. An example would be a query like “What is Python” and you want to find the paragraph “Python is an interpreted, high-level and general-purpose programming language. Python’s design philosophy …”. For asymmetric tasks, flipping the query and the entries in your corpus usually does not make sense.\n\nIt is critical that you choose the right model for your type of task.\n\n* https://sbert.net/examples/applications/semantic-search/README.html#util-semantic-search\n","metadata":{}},{"cell_type":"code","source":"\"\"\"\nThis is a simple application for sentence embeddings: semantic search\n\nWe have a corpus with various sentences. Then, for a given query sentence,\nwe want to find the most similar sentence in this corpus.\n\nThis script outputs for various queries the top 5 most similar sentences in the corpus.\n\"\"\"\n\nfrom sentence_transformers import SentenceTransformer, util\nimport torch\n\nembedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\n# Corpus with example sentences\ncorpus = [\n    \"A man is eating food.\",\n    \"A man is eating a piece of bread.\",\n    \"The girl is carrying a baby.\",\n    \"A man is riding a horse.\",\n    \"A woman is playing violin.\",\n    \"Two men pushed carts through the woods.\",\n    \"A man is riding a white horse on an enclosed ground.\",\n    \"A monkey is playing drums.\",\n    \"A cheetah is running behind its prey.\",\n]\ncorpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n\n# Query sentences:\nqueries = [\n    \"A man is eating pasta.\",\n    \"Someone in a gorilla costume is playing a set of drums.\",\n    \"A cheetah chases prey on across a field.\",\n]\n\n\n# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\ntop_k = min(5, len(corpus))\nfor query in queries:\n    query_embedding = embedder.encode(query, convert_to_tensor=True)\n\n    # We use cosine-similarity and torch.topk to find the highest 5 scores\n    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n    top_results = torch.topk(cos_scores, k=top_k)\n\n    print(\"\\n\\n======================\\n\\n\")\n    print(\"Query:\", query)\n    print(\"\\nTop 5 most similar sentences in corpus:\")\n\n    for score, idx in zip(top_results[0], top_results[1]):\n        print(corpus[idx], \"(Score: {:.4f})\".format(score))\n\n    \"\"\"\n    # Alternatively, we can also use util.semantic_search to perform cosine similarty + topk\n    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n    hits = hits[0]      #Get the hits for the first query\n    for hit in hits:\n        print(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))\n    \"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-15T02:00:53.733654Z","iopub.execute_input":"2024-04-15T02:00:53.734775Z","iopub.status.idle":"2024-04-15T02:01:08.535548Z","shell.execute_reply.started":"2024-04-15T02:00:53.734719Z","shell.execute_reply":"2024-04-15T02:01:08.534242Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b29fcaf6800429898a7a6d86a588c8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0d9dd4598eb4457bddbaaeee8faef22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ebaf8e54317430289f323abb34a55b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50b712a87d4f4d8eab135b2cbe2ea918"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8f5d70d84474da7ad8ac428bf574193"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"171f74da7c274dfb9e067eed06137d76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7b3492483614a549030536a41b9e601"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da3457d89cbe4699bce8cf4fe911e53e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32e767ecbf8e47199749e6f014d7afd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cb6e56c03004b768d76fa3af5f81a18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0acc53489fe4fc78c6a909d8a8a78e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0f5dff964594011afa6cc99dbd6e5f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a7ee8aac42948a39249f2a0130fac9a"}},"metadata":{}},{"name":"stdout","text":"\n\n======================\n\n\nQuery: A man is eating pasta.\n\nTop 5 most similar sentences in corpus:\nA man is eating food. (Score: 0.7035)\nA man is eating a piece of bread. (Score: 0.5272)\nA man is riding a horse. (Score: 0.1889)\nA man is riding a white horse on an enclosed ground. (Score: 0.1047)\nA cheetah is running behind its prey. (Score: 0.0980)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ab9354e232d499e951611f5c2490217"}},"metadata":{}},{"name":"stdout","text":"\n\n======================\n\n\nQuery: Someone in a gorilla costume is playing a set of drums.\n\nTop 5 most similar sentences in corpus:\nA monkey is playing drums. (Score: 0.6433)\nA woman is playing violin. (Score: 0.2564)\nA man is riding a horse. (Score: 0.1389)\nA man is riding a white horse on an enclosed ground. (Score: 0.1191)\nA cheetah is running behind its prey. (Score: 0.1080)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7006929dda34d688c6010148bb932f9"}},"metadata":{}},{"name":"stdout","text":"\n\n======================\n\n\nQuery: A cheetah chases prey on across a field.\n\nTop 5 most similar sentences in corpus:\nA cheetah is running behind its prey. (Score: 0.8253)\nA man is eating food. (Score: 0.1399)\nA monkey is playing drums. (Score: 0.1292)\nA man is riding a white horse on an enclosed ground. (Score: 0.1097)\nA man is riding a horse. (Score: 0.0650)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Approximate Nearest Neighbor\nSearching a large corpus with millions of embeddings can be time-consuming if exact nearest neighbor search is used (like it is used by util.semantic_search).\n\nIn that case, Approximate Nearest Neighbor (ANN) can be helpful. Here, the data is partitioned into smaller fractions of similar embeddings. This index can be searched efficiently and the embeddings with the highest similarity (the nearest neighbors) can be retrieved within milliseconds, even if you have millions of vectors.\n\nHowever, the results are not necessarily exact. It is possible that some vectors with high similarity will be missed. That’s the reason why it is called approximate nearest neighbor.\n\nFor all ANN methods, there are usually one or more parameters to tune that determine the recall-speed trade-off. If you want the highest speed, you have a high chance of missing hits. If you want high recall, the search speed decreases.\n\nThree popular libraries for approximate nearest neighbor are Annoy, FAISS, and hnswlib. Personally I find hnswlib the most suitable library: It is easy to use, offers a great performance and has nice features included that are important for real applications.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}