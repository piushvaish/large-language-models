{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.pinecone.io/learn/sentence-embeddings/\n",
    "# https://www.youtube.com/watch?v=WS1uVMGhlWQ&list=PLIUOU7oqGTLgz-BI8bNMVGwQxIMuQddJO&index=2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output we can see here is the SentenceTransformer object which contains three components:\n",
    "\n",
    "The transformer itself, here we can see the max sequence length of 128 tokens and whether to lowercase any input (in this case, the model does not). We can also see the model class, BertModel.\n",
    "\n",
    "The pooling operation, here we can see that we are producing a 768-dimensional sentence embedding. We are doing this using the mean pooling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"the fifty mannequin heads floating in the pool kind of freaked them out\",\n",
    "    \"she swore she just saw her sushi move\",\n",
    "    \"he embraced his new life as an eggplant\",\n",
    "    \"my dentist tells me that chewing bricks is very bad for your teeth\",\n",
    "    \"the dental specialist recommended an immediate stop to flossing with construction materials\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Adam\",\n",
    "    \"Eve\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "embeddings.shape\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(embeddings[0], embeddings[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.409143  , 1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.10909013, 0.44547972, 1.        , 0.        , 0.        ],\n",
       "       [0.50074863, 0.30693939, 0.20791632, 1.        , 0.        ],\n",
       "       [0.29936197, 0.38607213, 0.28499264, 0.63849485, 1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have calculated the cosine similarity between every combination of our five sentence embeddings\n",
    "import numpy as np\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "sim = np.zeros((len(sentences), len(sentences)))\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sim[i:,i] = cos_sim(embeddings[i], embeddings[i:])\n",
    "\n",
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last row shows the comparison between the sentences. You can create a heatmap to visualize the cosine better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.13575410842895508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1175,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fda88456f64544addf2e3aa60cd78c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.09947896003723145,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 190,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae53cb9071de47ee8b27b7f1e5efae82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.12063884735107422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 10571,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d51f81018243f4971e59f47b18c267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.09785771369934082,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 571,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57d7f5ebc0e4e7a8a2611ee69351fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0913093090057373,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 116,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368919890a4e4244b349390232f27204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.09834861755371094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 39265,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3364ec378940949c76d33e71a93dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.05925941467285156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 438011953,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce542e41113149c9a20ffab1a99be1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.14325547218322754,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 53,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17d26fea4054d97892dbe190c3fd154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.10025858879089355,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 239,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa70e46b5094501b7b44c4f78ab2623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.10369729995727539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 466021,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07f5d392fa941cdbe40e9654978aebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.09058451652526855,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 363,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8781efe8806845be92cfae190b50aae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.08084225654602051,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 13123,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63175f93d71a4e89818ce55c501530a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.09490180015563965,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 231536,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a38f08bc7e74a63ab683bdb53e6bd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0484766960144043,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 349,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5964f7b90e39408885d5e3c1545d39ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "mpnet = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "mpnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000012,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.26406276,  1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.1650348 ,  0.16126674,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.04334446,  0.04615863,  0.05670125,  0.99999994,  0.        ],\n",
       "       [ 0.05398511,  0.06101185, -0.01122269,  0.51847208,  1.00000012]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = mpnet.encode(sentences)\n",
    "\n",
    "sim = np.zeros((len(sentences), len(sentences)))\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sim[i:,i] = cos_sim(embeddings[i], embeddings[i:])\n",
    "\n",
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The semantic representation of later models is apparent. Although SBERT correctly identifies 4 and 3 as the most similar pair, it also assigns reasonably high similarity to other sentence pairs.\n",
    "\n",
    "On the other hand, the MPNet model makes a very clear distinction between similar and dissimilar pairs, with most pairs scoring less than 0.1 and the 4-3 pair scored at 0.52.\n",
    "\n",
    "By increasing the separation between dissimilar and similar pairs, we’re:\n",
    "\n",
    "* Making it easier to automatically identify relevant pairs.\n",
    "* Pushing predictions closer to the 0 and 1 target scores for dissimilar and similar pairs used during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity Notes\n",
    "Cosine similarity is a metric used to measure how similar the documents are irrespective of their size. Mathematically, it measures the cosine of the angle between two vectors projected in a multi-dimensional space.\n",
    "\n",
    "The cosine similarity is advantageous because even if the two similar documents are far apart by the Euclidean distance (due to the size of the document), chances are they may still be oriented closer together. The smaller the angle, higher the cosine similarity.\n",
    "\n",
    "Smaller angles between vectors produce larger cosine values, indicating greater cosine similarity. For example: When two vectors have the same orientation, the angle between them is 0, and the cosine similarity is 1. Perpendicular vectors have a 90-degree angle between them and a cosine similarity of 0.\n",
    "\n",
    "The cosine similarity is described mathematically as the division between the dot product of vectors and the product of the euclidean norms or magnitude of each vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Natural Language Inference (NLI)\n",
    "\n",
    "NLI focus on identifying sentence pairs that infer or do not infer one another. We will use two of these datasets; the Stanford Natural Language Inference (SNLI) and Multi-Genre NLI (MNLI) corpora.\n",
    "\n",
    "Merging these two corpora gives us 943K sentence pairs (550K from SNLI, 393K from MNLI). All pairs include a premise and a hypothesis, and each pair is assigned a label:\n",
    "\n",
    "* 0 — entailment, e.g. the premise suggests the hypothesis.\n",
    "* 1 — neutral, the premise and hypothesis could both be true, but they are not necessarily related.\n",
    "* 2 — contradiction, the premise and hypothesis contradict each other.\n",
    "\n",
    "* https://www.pinecone.io/learn/train-sentence-transformers-softmax/\n",
    "* https://www.youtube.com/watch?v=aSx0jg9ZILo&list=PLIUOU7oqGTLgz-BI8bNMVGwQxIMuQddJO&index=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (C:\\Users\\piush\\.cache\\huggingface\\datasets\\snli\\plain_text\\1.0.0\\1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label'],\n",
       "    num_rows: 550152\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "snli = datasets.load_dataset('snli', split='train')\n",
    "\n",
    "snli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'premise': 'A person on a horse jumps over a broken down airplane.', 'hypothesis': 'A person is training his horse for a competition.', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "print(snli[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (C:\\Users\\piush\\.cache\\huggingface\\datasets\\glue\\mnli\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "    num_rows: 392702\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_nli = datasets.load_dataset('glue', 'mnli', split='train')\n",
    "\n",
    "m_nli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\piush\\.cache\\huggingface\\datasets\\snli\\plain_text\\1.0.0\\1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b\\cache-b5fc5c7da89ce7e6.arrow\n"
     ]
    }
   ],
   "source": [
    "m_nli = m_nli.remove_columns(['idx'])\n",
    "snli = snli.cast(m_nli.features)\n",
    "dataset = datasets.concatenate_datasets([snli, m_nli])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both datasets contain -1 values in the label feature where no confident class could be assigned. We remove them using the filter method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\piush\\.cache\\huggingface\\datasets\\snli\\plain_text\\1.0.0\\1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b\\cache-0372113c5208bfb5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942854\n",
      "942069\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "# there are -1 values in the label feature, these are where no class could be decided so we remove\n",
    "dataset = dataset.filter(\n",
    "    lambda x: 0 if x['label'] == -1 else 1\n",
    ")\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must convert our human-readable sentences into transformer-readable tokens, so we go ahead and tokenize our sentences. Both premise and hypothesis features must be split into their own input_ids and attention_mask tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015682458877563477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 943,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6ebbdad2fb4ea8a6a596dec37dc048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/943 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014401912689208984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 943,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf45552cb06146608549416990a15b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/943 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\piush\\Desktop\\nlp-notes\\nlp\\notebooks\\semantic_search_course.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m all_cols \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mpremise\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhypothesis\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mlambda\u001b[39;49;00m x: tokenizer(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             x[part], max_length\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m             truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         ), batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mrename_column(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m             col, part\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mcol\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\datasets\\arrow_dataset.py:2387\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   2384\u001b[0m disable_tqdm \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled()\n\u001b[0;32m   2386\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m num_proc \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 2387\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_single(\n\u001b[0;32m   2388\u001b[0m         function\u001b[39m=\u001b[39;49mfunction,\n\u001b[0;32m   2389\u001b[0m         with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[0;32m   2390\u001b[0m         with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[0;32m   2391\u001b[0m         input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[0;32m   2392\u001b[0m         batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[0;32m   2393\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2394\u001b[0m         drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[0;32m   2395\u001b[0m         remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[0;32m   2396\u001b[0m         keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[0;32m   2397\u001b[0m         load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[0;32m   2398\u001b[0m         cache_file_name\u001b[39m=\u001b[39;49mcache_file_name,\n\u001b[0;32m   2399\u001b[0m         writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[0;32m   2400\u001b[0m         features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m   2401\u001b[0m         disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[0;32m   2402\u001b[0m         fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[0;32m   2403\u001b[0m         new_fingerprint\u001b[39m=\u001b[39;49mnew_fingerprint,\n\u001b[0;32m   2404\u001b[0m         disable_tqdm\u001b[39m=\u001b[39;49mdisable_tqdm,\n\u001b[0;32m   2405\u001b[0m         desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[0;32m   2406\u001b[0m     )\n\u001b[0;32m   2407\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2409\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\datasets\\arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    556\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 557\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    558\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    559\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[0;32m    560\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\datasets\\arrow_dataset.py:524\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    517\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[0;32m    518\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[0;32m    519\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[0;32m    520\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[0;32m    521\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[0;32m    522\u001b[0m }\n\u001b[0;32m    523\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 524\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    525\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    526\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\datasets\\fingerprint.py:480\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[0;32m    478\u001b[0m \u001b[39m# Call actual function\u001b[39;00m\n\u001b[1;32m--> 480\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    482\u001b[0m \u001b[39m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[39mif\u001b[39;00m inplace:  \u001b[39m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\datasets\\arrow_dataset.py:2767\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[0;32m   2765\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2766\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m-> 2767\u001b[0m         batch \u001b[39m=\u001b[39m input_dataset\u001b[39m.\u001b[39;49m_getitem(\n\u001b[0;32m   2768\u001b[0m             \u001b[39mslice\u001b[39;49m(i, i \u001b[39m+\u001b[39;49m batch_size),\n\u001b[0;32m   2769\u001b[0m             decoded\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   2770\u001b[0m         )\n\u001b[0;32m   2771\u001b[0m         indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2772\u001b[0m             \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(input_dataset\u001b[39m.\u001b[39mnum_rows)))\n\u001b[0;32m   2773\u001b[0m         )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[0;32m   2774\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\datasets\\arrow_dataset.py:2150\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[0;32m   2148\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, decoded\u001b[39m=\u001b[39mdecoded, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[0;32m   2149\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data, key, indices\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 2150\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[0;32m   2151\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39;49mformatter, format_columns\u001b[39m=\u001b[39;49mformat_columns, output_all_columns\u001b[39m=\u001b[39;49moutput_all_columns\n\u001b[0;32m   2152\u001b[0m )\n\u001b[0;32m   2153\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\datasets\\formatting\\formatting.py:540\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m     pa_table_to_format \u001b[39m=\u001b[39m pa_table\u001b[39m.\u001b[39mdrop(col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m pa_table\u001b[39m.\u001b[39mcolumn_names \u001b[39mif\u001b[39;00m col \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m format_columns)\n\u001b[1;32m--> 540\u001b[0m     formatted_output \u001b[39m=\u001b[39m formatter(pa_table_to_format, query_type\u001b[39m=\u001b[39;49mquery_type)\n\u001b[0;32m    541\u001b[0m     \u001b[39mif\u001b[39;00m output_all_columns:\n\u001b[0;32m    542\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(formatted_output, MutableMapping):\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\datasets\\formatting\\formatting.py:285\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_column(pa_table)\n\u001b[0;32m    284\u001b[0m \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_batch(pa_table)\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\datasets\\formatting\\formatting.py:322\u001b[0m, in \u001b[0;36mPythonFormatter.format_batch\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_batch\u001b[39m(\u001b[39mself\u001b[39m, pa_table: pa\u001b[39m.\u001b[39mTable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m--> 322\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpython_arrow_extractor()\u001b[39m.\u001b[39;49mextract_batch(pa_table)\n\u001b[0;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoded:\n\u001b[0;32m    324\u001b[0m         batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_features_decoder\u001b[39m.\u001b[39mdecode_batch(batch)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_cols = ['label']\n",
    "\n",
    "for part in ['premise', 'hypothesis']:\n",
    "    dataset = dataset.map(\n",
    "        lambda x: tokenizer(\n",
    "            x[part], max_length=128, padding='max_length',\n",
    "            truncation=True\n",
    "        ), batched=True\n",
    "    )\n",
    "    for col in ['input_ids', 'attention_mask']:\n",
    "        dataset = dataset.rename_column(\n",
    "            col, part+'_'+col\n",
    "        )\n",
    "        all_cols.append(part+'_'+col)\n",
    "print(all_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all we need to do is prepare the data to be read into the model. To do this, we first convert the dataset features into PyTorch tensors and then initialize a data loader which will feed data into our model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\piush\\Desktop\\nlp-notes\\nlp\\notebooks\\semantic_search_course.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# covert dataset features to PyTorch tensors\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dataset\u001b[39m.\u001b[39mset_format(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m'\u001b[39m, columns\u001b[39m=\u001b[39mall_cols)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# initialize the dataloader\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# covert dataset features to PyTorch tensors\n",
    "dataset.set_format(type='torch', columns=all_cols)\n",
    "\n",
    "# initialize the dataloader\n",
    "batch_size = 16\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation\n",
    "When we train an SBERT model, we don’t need to start from scratch. We begin with an already pretrained BERT model (and tokenizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# start from a pretrained bert-base-uncased model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mean pooling function\n",
    "def mean_pool(token_embeds, attention_mask):\n",
    "    # reshape attention_mask to cover 768-dimension embeddings\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(\n",
    "        token_embeds.size()\n",
    "    ).float()\n",
    "    # perform mean-pooling but exclude padding tokens (specified by in_mask)\n",
    "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(\n",
    "        in_mask.sum(1), min=1e-9\n",
    "    )\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we would initialize the feed-forward NN first\n",
    "ffnn = torch.nn.Linear(768*3, 3)\n",
    "# then later in the code process our concatenated vector with it\n",
    "x = ffnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as before, we would initialize the loss function first\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "# then later in the code add them to the process\n",
    "x = loss_func(x, label)  # label is our *true* 0, 1, 2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "\n",
    "# we would initialize everything first\n",
    "optim = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "# and setup a warmup for the first ~10% steps\n",
    "total_steps = int(len(dataset) / batch_size)\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "\t\toptim, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1 epoch should be enough, increase if wanted\n",
    "for epoch in range(1):\n",
    "    model.train()  # make sure model is in training mode\n",
    "    # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # zero all gradients on each new step\n",
    "        optim.zero_grad()\n",
    "        # prepare batches and more all to the active device\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        # extract token embeddings from BERT\n",
    "        u = model(\n",
    "            inputs_ids_a, attention_mask=attention_a\n",
    "        )[0]  # all token embeddings A\n",
    "        v = model(\n",
    "            inputs_ids_b, attention_mask=attention_b\n",
    "        )[0]  # all token embeddings B\n",
    "        # get the mean pooled vectors\n",
    "        u = mean_pool(u, attention_a)\n",
    "        v = mean_pool(v, attention_b)\n",
    "        # build the |u-v| tensor\n",
    "        uv = torch.sub(u, v)\n",
    "        uv_abs = torch.abs(uv)\n",
    "        # concatenate u, v, |u-v|\n",
    "        x = torch.cat([u, v, uv_abs], dim=-1)\n",
    "        # process concatenated tensor through FFNN\n",
    "        x = ffnn(x)\n",
    "        # calculate the 'softmax-loss' between predicted and true label\n",
    "        loss = loss_func(x, label)\n",
    "        # using loss, calculate gradients and then optimize\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # update learning rate scheduler\n",
    "        scheduler.step()\n",
    "        # update the TDQM progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_path = './sbert_test_a'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)\n",
    "\n",
    "model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning With Sentence Transformers\n",
    "\n",
    "the sentence-transformers library has excellent support for those of us just wanting to train a model without worrying about the underlying training mechanisms.\n",
    "\n",
    "We don’t need to do much beyond a little data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (C:\\Users\\piush\\.cache\\huggingface\\datasets\\snli\\plain_text\\1.0.0\\1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n",
      "Reusing dataset glue (C:\\Users\\piush\\.cache\\huggingface\\datasets\\glue\\mnli\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Loading cached processed dataset at C:\\Users\\piush\\.cache\\huggingface\\datasets\\snli\\plain_text\\1.0.0\\1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b\\cache-b5fc5c7da89ce7e6.arrow\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.04045295715332031,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 943,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b834b0981cc475195b985d9e41b50fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/943 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# download\n",
    "snli = datasets.load_dataset('snli', split='train')\n",
    "mnli = datasets.load_dataset('glue', 'mnli', split='train')\n",
    "\n",
    "# format for merge\n",
    "mnli = mnli.remove_columns(['idx'])\n",
    "snli = snli.cast(mnli.features)\n",
    "\n",
    "# merge\n",
    "nli = datasets.concatenate_datasets([snli, mnli])\n",
    "del snli, mnli\n",
    "\n",
    "# and remove bad rows\n",
    "nli = nli.filter(\n",
    "    lambda x: False if x['label'] == -1 else True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017546892166137695,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 942069,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a0eb377e644627bc136a3b1d4216de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/942069 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import InputExample\n",
    "from tqdm.auto import tqdm  # so we see progress bar\n",
    "\n",
    "train_samples = []\n",
    "for row in tqdm(nli):\n",
    "    train_samples.append(InputExample(\n",
    "        texts=[row['premise'], row['hypothesis']],\n",
    "        label=row['label']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "loader = DataLoader(\n",
    "    train_samples, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need is the transformer model module, followed by a mean pooling module. The transformer models are loaded from HF, so we define bert-base-uncased as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "bert = models.Transformer('bert-base-uncased')\n",
    "pooler = models.Pooling(\n",
    "    bert.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True\n",
    ")\n",
    "\n",
    "model = SentenceTransformer(modules=[bert, pooler])\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our data, the model, and now we define how to optimize our model. Softmax loss is very easy to initialize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "loss = losses.SoftmaxLoss(\n",
    "    model=model,\n",
    "    sentence_embedding_dimension=model.get_sentence_embedding_dimension(),\n",
    "    num_labels=3)  # NLI dataset has [0, 1, 2] labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’re ready to train the model. We train for a single epoch and warm up for 10% of training as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 2.00 GiB total capacity; 1.58 GiB already allocated; 0 bytes free; 1.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\piush\\Desktop\\nlp-notes\\nlp\\notebooks\\semantic_search_course.ipynb Cell 39\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m warmup_steps \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(loader) \u001b[39m*\u001b[39m epochs \u001b[39m*\u001b[39m \u001b[39m0.1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     train_objectives\u001b[39m=\u001b[39;49m[(loader, loss)],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     warmup_steps\u001b[39m=\u001b[39;49mwarmup_steps,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X55sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     output_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./sbert_test_b\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X55sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piush/Desktop/nlp-notes/nlp/notebooks/semantic_search_course.ipynb#X55sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:724\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[0;32m    722\u001b[0m     loss_value\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m    723\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(loss_model\u001b[39m.\u001b[39mparameters(), max_grad_norm)\n\u001b[1;32m--> 724\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    726\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    728\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_scheduler:\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     64\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\optim\\optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\piush\\anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\optim\\adamw.py:148\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    146\u001b[0m state[\u001b[39m'\u001b[39m\u001b[39mexp_avg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(p, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mpreserve_format)\n\u001b[0;32m    147\u001b[0m \u001b[39m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m state[\u001b[39m'\u001b[39m\u001b[39mexp_avg_sq\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros_like(p, memory_format\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mpreserve_format)\n\u001b[0;32m    149\u001b[0m \u001b[39mif\u001b[39;00m amsgrad:\n\u001b[0;32m    150\u001b[0m     \u001b[39m# Maintains max of all exp. moving avg. of sq. grad. values\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(p, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mpreserve_format)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 2.00 GiB total capacity; 1.58 GiB already allocated; 0 bytes free; 1.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "warmup_steps = int(len(loader) * epochs * 0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(loader, loss)],\n",
    "    epochs=epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='./sbert_test_b',\n",
    "    show_progress_bar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare SBERT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"the fifty mannequin heads floating in the pool kind of freaked them out\",\n",
    "    \"she swore she just saw her sushi move\",\n",
    "    \"he embraced his new life as an eggplant\",\n",
    "    \"my dentist tells me that chewing bricks is very bad for your teeth\",\n",
    "    \"the dental specialist recommended an immediate stop to flossing with construction materials\",\n",
    "    \"i used to practice weaving with spaghetti three hours a day\",\n",
    "    \"the white water rafting trip was suddenly halted by the unexpected brick wall\",\n",
    "    \"the person would knit using noodles for a few hours daily\",\n",
    "    \"it was always dangerous to drive with him since he insisted the safety cones were a slalom course\",\n",
    "    \"the woman thinks she saw her raw fish and rice change position\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two new functions; sts_process to build the sentence embeddings and compare them with cosine similarity and sim_matrix to construct a similarity matrix from all possible pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# build embeddings and calculate cosine similarity\n",
    "def sts_process(sentence_a, sentence_b, model):\n",
    "    vecs = []  # init list of sentence vecs\n",
    "    for sentence in [sentence_a, sentence_b]:\n",
    "        # build input_ids and attention_mask tensors with tokenizer\n",
    "        input_ids = tokenizer(\n",
    "            sentence, max_length=512, padding='max_length',\n",
    "            truncation=True, return_tensors='pt'\n",
    "        )\n",
    "        # process tokens through model and extract token embeddings\n",
    "        token_embeds = model(**input_ids).last_hidden_state\n",
    "        # mean-pool token embeddings to create sentence embeddings\n",
    "        sentence_embeds = mean_pool(token_embeds, input_ids['attention_mask'])\n",
    "        vecs.append(sentence_embeds)\n",
    "    # calculate cosine similarity between pairs and return numpy array\n",
    "    return cos_sim(vecs[0], vecs[1]).detach().numpy()\n",
    "\n",
    "# controller function to build similarity matrix\n",
    "def sim_matrix(model):\n",
    "    # initialize empty zeros array to store similarity scores\n",
    "    sim = np.zeros((len(sentences), len(sentences)))\n",
    "    for i in range(len(sentences)):\n",
    "        # add similarity scores to the similarity matrix\n",
    "        sim[i:,i] = sts_process(sentences[i], sentences[i:], model)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('./sbert_test_a')\n",
    "\n",
    "sim = sim_matrix(model)  # build similarity scores matrix\n",
    "sns.heatmap(sim, annot=True)  # visualize heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these heatmaps, we ideally want all dissimilar pairs to have very low scores (near white) and similar pairs to produce distinctly higher scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67d509d7eba20331265163425a81888951fd8dd61b2206587b199305e358c686"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
