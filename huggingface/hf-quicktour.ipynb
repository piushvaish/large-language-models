{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb\n# Transformers installation\n# ! pip install transformers datasets\n# You'll also need to install your preferred machine learning framework:\n\n#! pip install torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-28T16:38:39.958877Z","iopub.execute_input":"2024-03-28T16:38:39.959746Z","iopub.status.idle":"2024-03-28T16:38:52.029388Z","shell.execute_reply.started":"2024-03-28T16:38:39.959707Z","shell.execute_reply":"2024-03-28T16:38:52.028485Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title\nfrom IPython.display import HTML\n\nHTML('')","metadata":{"execution":{"iopub.status.busy":"2024-03-28T16:39:25.494130Z","iopub.execute_input":"2024-03-28T16:39:25.494545Z","iopub.status.idle":"2024-03-28T16:39:25.503009Z","shell.execute_reply.started":"2024-03-28T16:39:25.494511Z","shell.execute_reply":"2024-03-28T16:39:25.502076Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"# https://huggingface.co/docs/transformers/main/en/main_classes/pipelines\nfrom transformers import pipeline\n\nclassifier = pipeline(\"sentiment-analysis\")","metadata":{"execution":{"iopub.status.busy":"2024-03-28T16:54:26.595684Z","iopub.execute_input":"2024-03-28T16:54:26.596082Z","iopub.status.idle":"2024-03-28T16:55:05.615093Z","shell.execute_reply.started":"2024-03-28T16:54:26.596051Z","shell.execute_reply":"2024-03-28T16:55:05.614172Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-03-28 16:54:40.784760: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-28 16:54:40.784870: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-28 16:54:41.090499: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nNo model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f11cfc4fd1cc4fb28ffec939d746189f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e87a244c115446e857468568c5eb061"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aa0b0dbedf94ad4a5d16aa8254d5845"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e99127f02c248d795bbca43389ddecb"}},"metadata":{}}]},{"cell_type":"code","source":"pipe = pipeline(model=\"FacebookAI/roberta-large-mnli\")\npipe(\"This restaurant is awesome\")","metadata":{"execution":{"iopub.status.busy":"2024-03-28T16:55:25.226775Z","iopub.execute_input":"2024-03-28T16:55:25.227447Z","iopub.status.idle":"2024-03-28T16:55:34.583319Z","shell.execute_reply.started":"2024-03-28T16:55:25.227416Z","shell.execute_reply":"2024-03-28T16:55:34.582234Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efd0bd9e3bed44a184bda80e520fc079"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.43G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06904d19753a4377b6ff56771cff7d3d"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at FacebookAI/roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50425abd1c2e44fbbb8f7f6a055fd7bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54ff9224987c49af90b4e5da17f5fdd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be97843f365425e810ebd56e02602b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f9592d50f604dd684587bbb6fd8e587"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[{'label': 'NEUTRAL', 'score': 0.7313140630722046}]"},"metadata":{}}]},{"cell_type":"code","source":"classifier(\"We are very happy to show you the ðŸ¤— Transformers library.\")","metadata":{"execution":{"iopub.status.busy":"2024-03-28T16:56:32.905683Z","iopub.execute_input":"2024-03-28T16:56:32.906609Z","iopub.status.idle":"2024-03-28T16:56:32.963388Z","shell.execute_reply.started":"2024-03-28T16:56:32.906572Z","shell.execute_reply":"2024-03-28T16:56:32.962398Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"},"metadata":{}}]},{"cell_type":"code","source":"results = classifier([\"We are very happy to show you the ðŸ¤— Transformers library.\", \"We hope you don't hate it.\"])\nfor result in results:\n    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-28T16:56:49.758533Z","iopub.execute_input":"2024-03-28T16:56:49.758941Z","iopub.status.idle":"2024-03-28T16:56:49.837774Z","shell.execute_reply.started":"2024-03-28T16:56:49.758910Z","shell.execute_reply":"2024-03-28T16:56:49.836856Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"label: POSITIVE, with score: 0.9998\nlabel: NEGATIVE, with score: 0.5309\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Use another model and tokenizer in the pipeline","metadata":{}},{"cell_type":"code","source":"model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"","metadata":{"execution":{"iopub.status.busy":"2024-03-28T16:57:51.033877Z","iopub.execute_input":"2024-03-28T16:57:51.034720Z","iopub.status.idle":"2024-03-28T16:57:51.038566Z","shell.execute_reply.started":"2024-03-28T16:57:51.034685Z","shell.execute_reply":"2024-03-28T16:57:51.037675Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n     ","metadata":{"execution":{"iopub.status.busy":"2024-03-28T16:58:04.517228Z","iopub.execute_input":"2024-03-28T16:58:04.517583Z","iopub.status.idle":"2024-03-28T16:58:09.675372Z","shell.execute_reply.started":"2024-03-28T16:58:04.517557Z","shell.execute_reply":"2024-03-28T16:58:09.674559Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31bfa5e3c536455692530b62ad84526c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4607c3ee07cb4a66aacc0f9339a8d76a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23112bdf413a472c80aa078f9dc0bf1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b82f5fe91954367a7808fc38ff9978f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60f83cff0ada427b90d7bdd7dcde6c68"}},"metadata":{}}]},{"cell_type":"code","source":"classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\nclassifier(\"Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ðŸ¤— Transformers.\")","metadata":{"execution":{"iopub.status.busy":"2024-03-28T16:59:02.763080Z","iopub.execute_input":"2024-03-28T16:59:02.763446Z","iopub.status.idle":"2024-03-28T16:59:02.850932Z","shell.execute_reply.started":"2024-03-28T16:59:02.763418Z","shell.execute_reply":"2024-03-28T16:59:02.849997Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[{'label': '5 stars', 'score': 0.7272651791572571}]"},"metadata":{}}]},{"cell_type":"markdown","source":"AutoClass","metadata":{}},{"cell_type":"code","source":"encoding = tokenizer(\"We are very happy to show you the ðŸ¤— Transformers library.\")\nprint(encoding)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T17:00:21.402559Z","iopub.execute_input":"2024-03-28T17:00:21.402936Z","iopub.status.idle":"2024-03-28T17:00:21.409087Z","shell.execute_reply.started":"2024-03-28T17:00:21.402904Z","shell.execute_reply":"2024-03-28T17:00:21.407824Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","output_type":"stream"}]},{"cell_type":"code","source":"pt_batch = tokenizer(\n    [\"We are very happy to show you the ðŸ¤— Transformers library.\", \"We hope you don't hate it.\"],\n    padding=True,\n    truncation=True,\n    max_length=512,\n    return_tensors=\"pt\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T17:00:55.135267Z","iopub.execute_input":"2024-03-28T17:00:55.136191Z","iopub.status.idle":"2024-03-28T17:00:55.141790Z","shell.execute_reply.started":"2024-03-28T17:00:55.136150Z","shell.execute_reply":"2024-03-28T17:00:55.140841Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"pt_batch","metadata":{"execution":{"iopub.status.busy":"2024-03-28T17:01:02.262004Z","iopub.execute_input":"2024-03-28T17:01:02.262405Z","iopub.status.idle":"2024-03-28T17:01:02.270538Z","shell.execute_reply.started":"2024-03-28T17:01:02.262376Z","shell.execute_reply":"2024-03-28T17:01:02.269562Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[  101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103,   100,\n         58263, 13299,   119,   102],\n        [  101, 11312, 18763, 10855, 11530,   112,   162, 39487, 10197,   119,\n           102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}"},"metadata":{}}]},{"cell_type":"code","source":"pt_outputs = model(**pt_batch)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T17:02:12.746917Z","iopub.execute_input":"2024-03-28T17:02:12.747652Z","iopub.status.idle":"2024-03-28T17:02:12.825467Z","shell.execute_reply.started":"2024-03-28T17:02:12.747621Z","shell.execute_reply":"2024-03-28T17:02:12.824438Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"pt_outputs","metadata":{"execution":{"iopub.status.busy":"2024-03-28T17:02:45.808943Z","iopub.execute_input":"2024-03-28T17:02:45.809299Z","iopub.status.idle":"2024-03-28T17:02:45.850763Z","shell.execute_reply.started":"2024-03-28T17:02:45.809274Z","shell.execute_reply":"2024-03-28T17:02:45.849910Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"SequenceClassifierOutput(loss=None, logits=tensor([[-2.6222, -2.7745, -0.8967,  2.0137,  3.3064],\n        [ 0.0064, -0.1258, -0.0503, -0.1655,  0.1329]],\n       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"},"metadata":{}}]},{"cell_type":"code","source":"from torch import nn\n\npt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\nprint(pt_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T17:03:35.442563Z","iopub.execute_input":"2024-03-28T17:03:35.443250Z","iopub.status.idle":"2024-03-28T17:03:35.449343Z","shell.execute_reply.started":"2024-03-28T17:03:35.443218Z","shell.execute_reply":"2024-03-28T17:03:35.448475Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}